\section{Descripción de la solución}
\begin{comment}
En la presente sección se describe el estado del arte y las características de la solución. Se explicara cual es el propósito de la solución, y posteriormente los alcances y limitaciones establecidas.
\end{comment}

\subsection{Estado del arte}
Muchos de los métodos utilizados \cite{Elman1990, Schmidhuber1992b, Pearlmutter1989, Pearlmutter1995} sufren del desvanecimiento del gradiente. Para solventar el problema hay diversos métodos que lo evitan.
%% 13. S. E. Fahlman, "The recurrent cascade-correlation learning algorithm", in Advances in Neural Information Processing Systems 3, ed. R. P. Lippmann et al. (Morgan Kaufmann, San Mateo, 1991), pages 190-196.

% 14. R. J. Williams, "Complexity of exact gradient computation algorithms for recurrent neural networks" , Technical Report NU-CCS-89-27, Boston: Northeastern Univ., College of Computer Science, 1989.

%% 15. J. Schmidhuber, "A fixed size storage O(n^3) time complexity learning algorithm for fully recurrent continually running networks", Neural Computation, 4(2).243-248 (1992).

%% 16. B. A. Pearlmutter, "Learning state space trajectories in recurrent neural networks", Neural Computation, 1(2):263{269 (1989).

%% 17B. A. Pearlmutter, "Gradient calculations for dynamic recurrent neural networks: A survey", IEEE Transactions on Neural Networks, 6(5):1212{1228 (1995).


\subsubsection{Métodos de búsqueda global}
Los métodos de búsqueda global no utilizan el gradiente. Métodos como {\em simulated annealing} (SA), {\em multi-grid random search} \cite{Bengio1994} y {\em random weight guessing} \cite{Schmidhuber1996} han sido investigados. Se ha encontrado que los métodos de búsquedas globales funcionan bien en problemas que involucren dependencias a largo plazo y que además utilizan redes que contienen pocos parámetros y no precisan de alta precisión en sus calculos.

El método SA es un algoritmo de búsqueda meta-heurística para problemas de optimización global. La técnica está basada en el proceso de calentamiento de un metal, vidrio o cristal hasta su punto de fusión, para luego enfriarlo hasta obtener una estructura cristalina. El algoritmo \ref{alg:sa} decribe el procedimiento de la siguiente manera: dada una solución inicial se genera un conjunto de soluciones que son una perturbación de la solución actual, al evaluar cada perturbación se actualizará la solución actual en caso de que la perturbación sea mejor que la solución actual, y en caso contrario, existirá una probabilidad de que la solución actual sea actualizada de igual manera.

\scalebox{0.8}{\begin{algorithm}[H]
    \SetAlgoLined
	\DontPrintSemicolon
	\KwData{Temperatura $T$, constante de Boltzmann $k$, factor de reducción $c$}
	Seleccionar el mejor vector solución $x_{0}$ a optimizar\;
	\While{El criterio no se cumpla}{
		\While{Existan soluciones en el conjunto}{
			Seleccionar una solución $x_{0} + \Delta x$\;
			\uIf{$f(x_{0} + \Delta x) < f(x_{0})$}{
				$f_{new} = f(x_{0} + \Delta x)$; $x_{0} = x_{0} + \Delta x$\;
			}
			\Else{
				$\Delta f = f(x_{0} + \Delta x) - f(x_{0})$\;
				\uIf{$rand(0, 1) > \exp{(-\Delta f/kT}$)}{
					$f_{new} = f(x_{0} + \Delta x)$; $x_{0} = x_{0} + \Delta x$\;
				}\Else{
					$f_{new} = f(x_{0})$\;
				}
			}
			$f = f_{new}$; $T = cT$\;
		}
	}
	\caption{Simulated annealing}
	\label{alg:sa}
\end{algorithm}}



% [1998b] Hochreiter
% Y. Bengio, P. Simard, and P. Frasconi, "Learning long-term dependencies with gradient descent is dicult", IEEE Transactions on Neural Networks, 5(2):157{166 (1994).
%\subsubsection{(ii) Métodos que refuerzan el gradiente}
%Los valores más grandes del gradiente pueden ser reforzados por la optimización pseudo-Newton ponderada en el tiempoy la propagación discreta del errror \cite{Bengio1994}. Presentan problemas para almacenar información real de gran valor en el tiempo.

%\subsubsection{(iii) Métodos que operan en niveles mas altos}
%Anteriormente se ha propuesto un enfoque EM para la propagación del objetivo \cite{Bengio1993}. Este enfoque utiliza un número discreto de estados y, por lo tanto, tendrá problemas con valores continuos.
%Las técnicas de filtrado de Kallman se utilizan para el entrenamiento de redes recurrentes \cite{Puskorius1994}. Sin embargo, un factor de descuento derivado conduce a problemas de desvanecimiento del gradiente.
%Si un problema de retraso a largo plazo contiene regularidades locales, un sistema jerárquico chunket funciona bien \cite{Schmidhuber1992a}.

%\subsubsection{(iv) Métodos que utilizan arquitecturas especiales}
\subsubsection{El modelo de memoria a corto y largo plazo}
\citeA{Hochreiter1997a} introdujeron el modelo de memoria a corto y largo plazo ({\em Long short-term memory}, LSTM) como solución al problema del devanecimiento del gradiente. La red LSTM se basa en el bloque de memoria, que se componse de una o más celdas de memoria, una compuerta de entrada y una compuerta de salida. Las entradas son unidades multiplicativas con activación continua y son compartidas por todas las celdas de un mismo bloque de memoria. Cada celda contiene una unidad lineal con una conexión recurrente local llamada carrusel de error constante (CEC), se conocerá como estado de la celda a la activación del CEC.

Cada celda recibe una entrada ponderada por los pesos correspondientes a la capa anterior. La compuerta de entrada se encarga de de permitir o impedir el acceso de estos valores al CEC del interior de la celda. La compuerta de salida realiza una acción similar sobre la salida de la celda, tolerando o reprimiendo la difusión del estado del CEC al resto de la red.

Los bloques de memoria configuran una red LSTM, donde no se indican los sesgos de las distintas neuronas del modelo. La existencia de las conexiones con pesos $W^{y, u}$  determina la naturaleza de la red. Así, si se permite la existencia de esta conexión, la red LSTM se puede considerar como una máquina neuronal de estados de MEaly, si no se permite, la red LSTM puede considerarse como una máquina nerupna de estados de Moore. El estado de la red LSTM está formado por las activaciones de las compuertas, el CEC y las celdas de los bloques de memoria.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LiuShenxiu.pdf
% Conquering vanishing gradient: Tensor Tree LSTM on aspect-sentiment classification
% - Tree-structures LSTMs
% - Tensor Tree LSTM


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lipton2015
% Truncated backpropagation through time (TBPTT) is one solution to the exploding gradient problem for continuously running networks [Williams and Zipser, 1989]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Squartini2003a
% PREPROCESSING BASED SOLUTION FOR THE VANISHING
% Squartini2003b
% Attempting to reduce the vanishing gradient effect through a novel recurrent multiscale architecture
\subsubsection{Preprocesamiento de la señal}
\citeA{Squartini2003a} propone pre-procesar la señal de entrada a través de una descomposición wavelet, buscando separar la información a corto plazo de la información a largo plazo, y entrenando diferentes NN. Los resultados son combinados para alcanzar el objetivo final. Este enfoque simplifica el proceso de aprendizaje de la NN, evitando cambios relevantes en la arquitectura de la red y las técnicas de aprendizaje.

\subsection{Características de la solución}
La solución propóne un análisis práctico de la convergencia de las redes neuronales profundas mediante la aplicación de la regla de aprendizaje basada en el algoritmo {\em simulated annealing}. El análisis se realizará sobre conjuntos de datos de diferente indole, utilizados en otras investigaciones. Se comparará su desempeño frente a otras reglas de aprendizaje definidas en la literatura.

\subsection{Propósitos de la solución}
El propósito del presente trabajo es analizar la convergencia de las redes neuronales profundas, determinando el comportamiento de diferentes reglas de aprendizaje.

%El propósito del presente trabajo es comparar los resultados del aprendizaje de los métodos dinámicos de la autorregulación cerebral en los seres humanos, determinando las características del proceso en función de las bandas de frecuencias y ruido.

\subsection{Alcances o limitaciones de la solución}
Los alcances y limitaciones descritos para el trabajo son los siguientes
\begin{itemize}
	\item El estudio se plantea desde una perspectiva práctica, precisando conjuntos de datos acotados.

    \item Los datos que se utilizarán son utilizados por \citeA{Morse2016} en su publicación.

	\item Se estudiarán las reglas de aprendizaje definidas por el gradiente estocástico y {\em simulated annealing}.

	\item Las redes neuronales utilizarán la misma configuración para todos los experimentos salvo por la regla de aprendizaje.
\end{itemize}
