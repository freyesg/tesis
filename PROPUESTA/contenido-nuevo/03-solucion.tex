\section{Descripción de la solución}
\begin{comment}
En la presente sección se describe el estado del arte y las características de la solución. Se explicara cual es el propósito de la solución, y posteriormente los alcances y limitaciones establecidas.
\end{comment}

\subsection{Estado del arte}
Muchos de los métodos utilizados (MUCHAS REFERENCIAS) sufren del desvanecimiento del gradiente. Para solventar el problema hay cuatro tipos de soluciones:
\begin{enumerate}
	\item Métodos que no utilizan el gradiente.
	\item Métodos que obligan el uso de gradiente mas altos.
	\item Métodos que operan en niveles mas altos.
	\item Métodos que utilizan arquitecturas especiales.
\end{enumerate}

(i) Los métodos de búsqueda global no utilizan el gradiente. Métodos como {\em simulated annealing}, {\em multi-grid random search} \cite{Bengio1994} y {\em random weight guessing} \cite{Schmidhuber1996} han sido investigados. Se ha encontrado que los métodos de búsquedas globales funcionan bien en problemas que involucren dependencias a largo plazo y que además utilizan redes que contienen pocos parámetros y no precisan de alta precisión en sus calculos.

% [1998b] Hochreiter
(ii) Los valores más grandes del gradiente pueden ser reforzados por la optimización pseudo-Newton ponderada en el tiempoy la propagación discreta del errror. Presentan problemas para almacenar información real de gran valor en el tiempo.

(iii) Anteriormente se ha propuesto un enfoque EM para la propagación del objetivo \cite{Bengio1993}. Este enfoque utiliza un número discreto de estados y, por lo tanto, tendrá problemas con valores continuos.

Las técnicas de filtrado de Kallman se utilizan para el entrenamiento de redes recurrentes \cite{Puskorius1994}. Sin embargo, un factor de descuento derivado conduce a problemas de desvanecimiento del gradiente.

Si un problema de retraso a largo plazo contiene regularidades locales, un sistema jerárquico chunket funciona bien \cite{Schmidhuber1992}.


Las redes de segundo orden (utilizando unidades sigma-pi) son, en principio, capaces de aumentar el flujo de error, pero los problemas derivados del desvanecimiento del gradiente difícilmente pueden evitarse ref-22-23.

Con una red neuronal con retardo ({\em Time-Delay Neural Network}, TDNN ref-24), las activaciones de la red de pasos de tiempo anteriores son devueltas a la red usando líneas de retardo fijo. En las TDNN la disminución de error se ralentiza porque el error utiliza "accesos rápidos" a medida que se propagan de nuevo. Las TDNN tienen que hacer frente a un trade-off: el aumento de la longitud de la línea de retardo aumenta el flujo de error, pero la red tiene más parámetros/unidades. Casos especiales de TDNN son las redes NARX ref-25, y la suma ponderada de los viejos activaciones en lugar de una línea de retardo fijo ref-26. Una versión más compleja de un TDNN, llamada "Memoria Gamma", se propuso red-27, pero su rendimiento en problemas que implican dependencias a largo plazo no parece ser mejor que el rendimiento de TDNNs.

En algunas arquitecturas, las constantes de tiempo determinan el factor de escala del error si se propaga de nuevo para un paso de tiempo en una sola unidad ref-3. Sin embargo, los intervalos de tiempo prolongado no se pueden procesar debido a que una constante de tiempo apropiada es casi imposible.

La actualización de una sola unidad mediante la adición de la antigua activación y la entrada de red actual escalada evita una fuga del gradiente ref-38. Pero el valor almacenado es sensible a las perturbaciones de insumos netos posteriores irrelevantes. La memoria de corto plazo ({\em Long Short Term Memory}, LSTM ref-10-11-1) utiliza una arquitectura especial para reforzar el flujo constante de errores a través de unidades especiales (incluyendo un mapeo de conservación de volumen). A diferencia del método que evita la fuga del gradiente ref-28 mencionado anteriormente, las perturbaciones por las señales irrelevantes actuales son impedidas por unidades multiplicativas.

\begin{comment}
La más frecuente técnica para inducir cambios rápidos y significativos en la \pam\, ha sido la deflación repentina de los manguitos sobre el muslo \citep{Aaslid1989, Aaslid1991,Lagi1994, Newell1994, Strebel1995, Tiecks1995a}. Con este enfoque, se colocan los manguitos alrededor de ambos muslos y se  genera una presión de \mmhg{20-40} por encima de la presión sistólica durante 2 minutos. Sin embargo, con una autorregulación normal la \cbfv\, vuelve y alcanza su estado basal antes que la \pam. \cite{Aaslid1989} demuestran que la velocidad de recuperación se ve afectada de manera significativa por los niveles de la \pacoo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% TRANSFER FUNCTION ANALYSIS %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
La evaluación de la \ca\, mediante el análisis de la función de transferencia está basado en minimizar, en la \ca, el efecto de la oscilación espontánea sobre la \cbfv. El método ha sido extensamente utilizado, por ejemplo, en la investivación del control cardiocasvular, arrítmia sinusal respiratoria y autoregulación renal \citep{Saul1989, Saul1991, Holstein1991}. El análisis espectral, al igual que la transformada rápida de Fourier, transforma la serie en el tiempo de la \bp\, y la \cbfv\, al dominio de la frecuencia. Entonces, la función de transferencia entre las dos señales se calcula como: $$ H(f) = \frac{S_{xy}(f)}{S_{xx}(f)} $$ donde $S_{xx}(f)$ es el autoespectro entre la señal de entrada, \bp, y la de señal de salida, \cbfv \citep{Ainslie2008}. Con la función de potencia relativa asociada (ganancia) y al tiempo (fase) puede ser descrito usando la parte real $H_{R}(f)$ y la parte imaginaria $H_{I}(f)$ de la función de transferencia compleja
\begin{eqnarray}
    \mbox{ganancia : } |H(f)| &=& \sqrt{|H_{R}(f)|^2 + |H_{I}(f)|^2}\\
    \mbox{fase : } \Phi(f) &=& \tan^{-1}\left(\frac{|H_{R}(f)|}{|H_{I}(f)|}\right)
\end{eqnarray}

Una estimación de la fiabilidad de la relación entre las dos señales se puede encontrar como la coherencia cuadrado:
\begin{eqnarray}
    \mbox{coherencia : } MSC(f) &=& \frac{|S_{xy}(f)|^2}{S_{xx}(f)S_{yy}(f)}
\end{eqnarray}
donde $S_{yy}(f)$ es el autoespectro del cambio en la \cbfv.



Como una representación de la relación lineal entre la fluctuación de la presión arterial y el flujo sanguíneo cerebral, la coherencia también se utiliza como una medida de \ca. Una coherencia cercana a cero indica que no hay relación entre la presión arterial y el flujo sanguíneo cerebral, mientras que una coherencia cercana a la unidad sugiere una relación lineal indicando problemas en la \ca.

En los primeros estudios de la \ca\, usando la función de transferencia y la fluctuación espontánea de la \bp, se obtuvieron las estimaciones de la respuesta de la frecuencia de amplitud (ganancia) y la coherencia, pero no la respuesta de frecuencia de fase \citep{Giller1990}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%% VOLTERRA %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
La presencia de no linealidades en la hemodinámica cerebral se ha sugerido en numerosos estudios \citep{Mitsis2002, Zhang1998, Mitsis2004a, Giller2003}. Por lo tanto, un modelo general de Volterra de dos entradas permitiría describir cuantitativamente los efectos dinámicos de la \abp\, espontánea media y la presión de \etcoo.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% RECURRENT NEURAL NETWORK %%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cite{Panerai2004} propone las redes neuronales recurrentes con retraso ({\em Time Lagged Recurrent Network}, TLRN) para modelar la relación dinámica entre la \pam\, y la \cbfv. Esta arquitectura particular, representa una visión general para explorar la aplicabilidad de una RNA para el modelamiento de la \cbf, debido a la flexibilidad de utilizar diferentes elementos de proceso ({\em Processing elements}, PE), que contiene información que permite modelar comportamiento dinámico. Memorias a corto plazo de Gamma y Laguerre han sido sugueridos como bloques de construcción para este fin.

La memoria de Laguerre es una combinación en cascada de filtros de paso bajo y paso todo. Las señales basales se obtienen de la convolución de la entrada del filtro de pasa bajo con un conjunto ortogonal de la función de paso todo, por lo cual la correlación de la base es menor que la de una memoria Gamma y la velocidad de adaptación aumenta. Cada filtro de paso todo coloca un cero en el círculo unitario, lo que indica el polo de la etapa anterior. Como resultado, la memoria de Laguerre no atenúa las señales de base.

La arquitectura propuesta por \cite{Panerai2004} posee una memoria Laguerre con tres entradas basales de \abp, una capa oculta con \pe\, no lineales conectados directamente a la \abp\, actual de base, las bases restantes de la memoria Laguerre, y los ciclos de retroalimentación de la memoria \cbfv. Se establece un umbral \pe\, para ajustar la salida. Finalmente, una capa de salida para la \cbfv\, contiene otra memoria Laguerre con tres bases con ciclos de retroalimentación de retardo a la capa oculta \pe.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% SUPPORT VECTOR MACHINE %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cite{Chacon2011} presenta un modelo basado en $v-SVM$, introducido por \cite{Scholkopf2000}. El algoritmo se basa en el aprendizaje estadístico que funciona como un tubo de radio $\varepsilon$ que encierra a los datos. La frontera de decisión que determina el radio $\varepsilon$ del tubo se obtiene mediante el uso de un subconjunto de ejemplos de entrenamiento llamado Vector de Soporte ({\em Support vector}, \sv). Si $\vec{x}$ representa al vector de datos de entrada, el valor de salida $f(\vec{x})$ está dado por la regresión \svm\, utilizando un vector de pesos $\vec{w}$

Una característica importante de las \svm\, es que ponen énfasis en la distancia de los datos a la línea de regresión utilizando funciones de pérdida, como la función de pérdida $\varepsilon$-sensitiva.

El algoritmo minimiza el riesgo funcional $||\vec{w}||^2$ a la que se añade una penalización dada por las variables de holgura $\xi$ dependiendo de la distancia del dato hasta la línea de regresión.

La variación de la $v-SVM$ de \cite{Scholkopf2000} consiste en agregar $\varepsilon$ al problema de minimización, ponderando por una variable $v$ que ajusta la contribución de $\varepsilon$ entre $0$ y $1$

La solución a este problema de minimización para obtener el vector de peso $\vec{w}$ se encuentra mediante el procedimiento estándar para un problema con restricciones de desigualdad en la aplicación de las condiciones de Kuhn-Tuker al problema dual. La principal ventaja del uso del parámetro $v$ es poder controlar el error y el número de \sv\, con un solo parámetro normalizado.

Para resolver el problema de la regresión no lineal basta con cambiar el producto interno entre dos variables independientes $\vec{x_i}\cdot\vec{x_j}$ por una función Kernel $K(\Phi(\vec{x_i})\cdot\Phi(\vec{x_j}))$. Algunas funciones Kernel que se puede utilizar puede ser la función de base radial gaussiano ($RBF$)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{comment}

\subsection{Características de la solución}
La solución propóne un análisis práctico de la convergencia de las redes neuronales profundas mediante la aplicación de la regla de aprendizaje basada en el algoritmo {\em simulated annealing}. El análisis se realizará sobre conjuntos de datos de diferente indole, utilizados en otras investigaciones. Se comparará su desempeño frente a otras reglas de aprendizaje definidas en la literatura.

\subsection{Propósitos de la solución}
El propósito del presente trabajo es analizar la convergencia de las redes neuronales profundas, determinando el comportamiento de diferentes reglas de aprendizaje.

%El propósito del presente trabajo es comparar los resultados del aprendizaje de los métodos dinámicos de la autorregulación cerebral en los seres humanos, determinando las características del proceso en función de las bandas de frecuencias y ruido.

\subsection{Alcances o limitaciones de la solución}
Los alcances y limitaciones descritos para el trabajo son los siguientes
\begin{itemize}
	\item El estudio se plantea desde una perspectiva práctica, precisando conjuntos de datos acotados.

    \item Los datos que se utilizarán son utilizados por \citeA{Morse2016} en su publicación.

	\item Se estudiarán las reglas de aprendizaje definidas por el gradiente estocástico y {\em simulated annealing}.

	\item Las redes neuronales utilizarán la misma configuración para todos los experimentos salvo por la regla de aprendizaje.
\end{itemize}
