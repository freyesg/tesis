% Deep Learning (Adaptive Computation and Machine Learning series)
%\chapter{INTRODUCCIÓN}
\chapter{Introducción}
\section{Antecedentes y motivación}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% lista3
El aprendizaje profundo ({\em Deep learning}, DL) se refiere a una nueva clase de métodos de las máquinas de aprendizaje ({\em Machine learning}, ML). El proceso ocurre a través de muchas capas distribuidas en una arquitectura jerárquica que se puede utilizar para clasificar un patrón y el aprendizaje de características \cite{Hinton2006, Bengio2009}. Esta arquitectura se inspira en la inteligencia artificial que emula el proceso de aprendizaje profundo y en capas de las áreas sensoriales primarias del neocórtex en el cerebro humano, que extrae automáticamente rasgos y abstracciones de los datos \cite{Bengio2007, Bengio2013, Arel2010}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% lista5
En los últimos años, se han desarrollado una serie de investigaciones en base a los algoritmos del DL en varios campos diferentes \cite{LeCun2015}. Ha sido utilizado para tareas de reconocimiento de imágenes \cite{Krizhevsky2012, Farabet2013, Tompson2014, Szegedy2015} y de reconocimiento de voz \cite{Mikolov2011, Hinton2012, Sainath2013}, y han superado otras técnicas de aprendizaje en la predicción de la actividad de las moléculas de fármacos \cite{Ma2015}, en el análisis de datos en el acelerador de partículas \cite{Ciodaro2012, Claire2015}, en la reconstrucción de los circuitos cerebrales \cite{Helmstaedter2013}, y en la predicción de los efectos de las mutaciones en el ADN no codificante en la expresión genética y en enfermedades \cite{Leung2014, Xiong2015}. También ha producido buenos resultados en diversas tareas para la comprensión del lenguaje natural \cite{Collobert2011}, en particular para la clasificación de temas, análisis de sentimientos, respuesta a preguntas \cite{Bordes2014} y en la traducción \cite{Jean2014, Sutskever2014}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% lista3
%En general, las técnicas del DL pueden clasificarse en modelos discriminativos profundos y modelos generativos \cite{Deng2014}. Ejemplos de modelos discriminativos son las redes neurales profundas ({\em Deep neural networks}, DNN), redes neuronales recurrentes ({\em Recurrent neural networks}, RNN) y redes neuronales convolucionales ({\em Convolutional neural networks}, CNN). Por otro lado, los modelos generativos, por ejemplo, son máquinas de Boltzmann restringidas ({\em Restricted Boltzmann machine}, RBMs), redes de creencias profundas ({\em Deep belief networks}, DBN), autocodificadores regularizados y máquinas profundas de Boltzmann (DBMs).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% lista2
% Revisar la última frase.
Es el surgimiento del DL que ha permitido que las redes neuronales artificiales ({\em Artificial Neural Networks}, NN) sean nuevamente estudiadas \cite{Bengio2006, Hinton2006, Le2012, Ranzato2007}. A pesar de que el nuevo enfoque abarca diversos algoritmos \cite{Bengio2007, Hinton2006}, un principio en común es que una NN con múltiples capas ocultas, que la convierten en profunda, puede codificar características más complejas en sus capas. Las NN fueron comunmente entrenadas a través del algoritmo de retropropagación \cite{Rumelhart1986b}, que utiliza el método del gradiente estocástico descendente ({\em Stochastics descent gradiente}, SGD), o una de sus variantes, para actualizar los pesos de la NN y de esa manera reducir el error total. El problema durante el proceso de aprendizaje de las NN es descrito como un problema de minimización de una función de error, la que depende de los pesos que conforman la red \cite{Rumelhart1986}. Este problema de optimización tiene la desventaja de ser no lineal, no convexo, además de tener mas de un mínimo local. Para solventar este problema se han desarrollado diversos algoritmos \cite{Grippo1994, Jacobs1988, Plagianakos2002, Rumelhart1986b, Plagianakos1998}  y su rendimiento varía según el problema a resolver. Por otra parte,  su estructura  le otorga la capacidad de aproximar cualquier función continua \cite{Hornik1991}, por lo tanto resuelven una amplia gama de problemas, como el reconocimiento de patrones \cite{Jain2000}, el agrupamiento y la clasificación \cite{Zhang2000}, la aproximación de funciones \cite{Selmic2002}, la bioinformática \cite{Mitra2006}, procesamiento de señales \cite{Hwang1997} y el procesamiento del habla \cite{Gorin1994}, entre otros.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% lista1
%Las NN han sido estudiadas y utilizadas en muchas aplicaciones de la inteligencia artificial. El problema durante el proceso de aprendizaje de las NN es descrito como un problema de minimización de una función de error, la que depende de los pesos que conforman la red \cite{Rumelhart1986}. Este problema de optimización tiene la desventaja de ser no lineal, no convexo, además de tener mas de un mínimo local. Para solventar este problema se han desarrollado diversos algoritmos \cite{Grippo1994, Jacobs1988, Plagianakos2002, Rumelhart1986b, Plagianakos1998}  y su rendimiento varía según el problema a resolver. Por otra parte,  su estructura  le otorga la capacidad de aproximar cualquier función continua \cite{Hornik1991}, por lo tanto resuelven una amplia gama de problemas, como el reconocimiento de patrones \cite{Jain2000}, el agrupamiento y la clasificación \cite{Zhang2000}, la aproximación de funciones \cite{Selmic2002}, la bioinformática \cite{Mitra2006}, procesamiento de señales \cite{Hwang1997} y el procesamiento del habla \cite{Gorin1994}, entre otros.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% lista1
El enfoque clásico para el entrenar NN es la aplicación de algoritmos basados en el gradiente, como la retropropagación \cite{Rumelhart1986b}. El algoritmo de retropropagación busca minimizar la función de error mediante el uso del gradiente. Aunque la función de error disminuye rápidamente en la dirección del gradiente negativo, la retropropagación es generalmente ineficiente y poco fiable \cite{Gori1992} debido a la superficie de error. Además, su rendimiento se ve afectado por parámetros que deben ser especificados por el usuario, pues no existe una base teórica para escogerlos \cite{Nguyen1990}. Dichos parámetros tienen una importancia crucial en el buen funcionamiento del algoritmo, por lo que el diseñador está obligado a seleccionar parámetros como los pesos iniciales de la NN, la topología de la red y la tasa de aprendizaje. En diversas investigaciones \cite{Cauchy1847, Grippo1994, Plagianakos1998, Plagianakos2002} ha quedado demostrado que pequeñas modificaciones en estos valores influyen en el rendimiento de la NN.

Para proporcionar una convergencia más rápida y estable se han desarrollado diversas variaciones y alternativas a la retroprogación. Algunos de estos métodos modifican el valor de algún término durante el proceso \cite{Jacobs1988, Rumelhart1986b} o de una tasa variable de aprendizaje \cite{Jacobs1988, Vogl1988}. \citeA{Magoulas1997,  Plagianakos1998} propusieron dos técnicas para evaluar en forma dinámica la tasa de aprendizaje y las evaluaciones de gradiente. El primero se basó en el algoritmo de Barzilai y Borwein \cite{Barzilai1988} que adapta la tasa de aprendizaje; mientras que el segundo utiliza estimaciones de la constante de Lipschitz, explotando la información local de la superficie de error y los pesos posteriores \cite{Magoulas1997}. Hay evidencias \cite{Magoulas1997, Plagianakos2002, Plagianakos1998} que han demostrado que la retropropagación con algoritmos que adaptan la velocidad del aprendizaje son robustas y tienen un buen rendimiento para el entrenamiento de NN.

Se han sugerido diversos métodos para mejorar la eficiencia del proceso de minimización del error. Algunos de los métodos utilizados son métodos de segundo orden como el gradiente conjugado \cite{Fletcher1964, Hestenes1952, Polak1969} y el quasi-Newton \cite{Huang1970, Nocedal2006}. Los métodos del gradiente conjugado utiliza una combinación lineal de la dirección de búsqueda anterior y el gradiente actual lo que produce una convergencia generalmente más rápida, es adecuado para redes neuronales de gran escala debido a su simplicidad, sus propiedades de convergencia y la poca memoria que requiere. En la literatura  se encuentran diversos métodos basados en el gradiente conjugado \cite{Birgin2001, Moller1993} que han sido utilizados para la construcción de NN en varias aplicaciones \cite{Charalambous1992, Peng2007, Sotiropoulos2002}. Los métodos quasi-Newton se consideran como los algoritmos más sofisticados para el entrenamiendo rápido de una NN. Definen la dirección de búsqueda mediante una aproximación de la matriz Hessiana, requiriendo información adicional. Se han propuesto diversas estrategias para  obtener una aproximación a la matriz Hessiana \cite{Al-Baali1998, Nocedal1993, Oren1972, Oren1974, Yin2007}; estas estrategias combinadas con búsquedas lineales han permitido definir una convergencia superlineal \cite{Yin2007}, mejorando significativamente el rendimiento de los métodos originales. Otras propuestas han utilizado capas de preentrenamiento \cite{Hinton2006b}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Debido a que la retropropagación suele minimizar una función de error no convexa con técnicas determinísticas locales (métodos de gradiente de primer y segundo orden), la probabilidad de converger a un mínimo local es alta \cite{Bianchini1996, Bishop1995, Battiti1995}. Este y otros problemas asociados con la retropropagación, como la convergencia lenta y la sobreejecución, podrían hacer que el proceso de aprendizaje fuera ineficiente. Para hacer frente a estos problemas han surgido técnicas para solucionarlo, algunas son del campo de la optimización global \cite{Battiti1995, Tsai2006, Rocha2003, Chelouah2000, Zheng2005}, además de técnicas metaheurísticas basadas en población \cite{Lamos2012}. Y es \citeA{Morse2016} quién retoma el uso de métodos metaheurísticos, esto sugiere que otros métodos, como el {\em Simulated annealing} (SA), pueden tener un buen desempeño estudiando problemas de minimización, de este modo se plantea que el SA tiene un desempeño computaciona competitivo frente al GSD al resolver instancias de un problema de regresión típica de la literatura

%Para la minimización de la función de error cuadrático medio BP, el método propuesto combina una técnica de búsqueda global basada en secuencias de puntos discretos [9], [10], y Nelder-Mead simplex local optimizer [11].


%sin embargo después recién en 2015 se retoma con ESTE PAPER, donde propone el uso de un método metaheurístico, esto sugiere que el SA puede tener un buen desempeño estudiando problemas de minimización, de este modo se plantea: SA tiene un desempeño computacional competitivo frente al GSD al resolver instancias de un problema de regresión tipica de la literatura (esto es la hipótesis nula)

%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Nos motiva el exito de las NN para predecir, nos motiva la dificultad del gradiente estocastico para minimizar el error en estos modelos no lineales complejos. Nos motiva la excelencia del SA en resolver problemas de optimización combinatoria que aparenemente pueden considerarse mas complejos que los problemas continuos.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%















\section{Descripción del problema}
% USAR [2003b] Squartini S, Hussain A, Piazza F
%La retropropagación basa su funcionamiento en multiplicaciones sucesivas basadas en el error para poder calcular los gradientes, y a medida que el error se propaga hacia la capa de entrada de la NN el gradiente comienza a disminuír su valor por cada capa que atraviesa. Esto significa que los pesos de las capas mas cercanas a la capa de entrada no sufrirán una actualización significativa, lo que representa un problema para redes profundas, ya que las capas mas cercanas a la capa de entrada necesitarán más tiempo para ser entrenadas.

El problema que se aborda en el presente trabajo presenta diversos estudios en la literatura, a pesar de esto siguen siendo un desafío computacional. Entre los últimos estudios relacionados existen algunos que utilizan programación genética, mostrando las bondades de las metaheurísticas al aplicarlas sobre las NN. A pesar de esto, no existen nuevos estudios que utilizen otras técnicas metaheurísticas para dar solución al problema que presenta la actualización de los pesos en el entrenamiento de las NN.

Para el desarrollo de este estudio se analiza la convergencia de una NN al entrenarla utilizando un método metaheurístico para minimizar el error. Para el desarrollo del estudio es preciso establecer si la convergencia ofrecida por el método ofrece un mejor desempeño respecto a métodos tradicionales y si es una alternativa que se deba considerar.

%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%el gap: han tenido un desempeño relevante para resolver problemas de optimización combinatoria. Sorprende que no hayan sido explorados estos métodos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% sin embargo después recién en 2015 se retoma con ESTE PAPER, donde propone el uso de un método metaheurístico, esto sugiere que el SA puede tener un buen desempeño estudiando problemas de minimización, de este modo se plantea: SA tiene un desempeño computacional competitivo frente al GSD al resolver instancias de un problema de regresión tipica de la literatura (esto es la hipótesis nula)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Solución propuesta}
\subsection{Características de la solución}
El método de aprendizaje basado en simmulated annealing permite la actualización de los pesos de la red. El método supone una alternativa a los métodos tradicionales de aprendizaje para la convergencia de los métodos debido a la independencia que otorga a la actualización de los pesos de las distintas capas y la capacidad de salir de los mínimos locales.

\subsection{Propósito de la solución}
El propósito de la solución es aportar en el campo de las redes neuronales y la clasificación de datos, proporcionando un análisis comparativo de la convergencia de un método metaheuristico aplicado sobre las NN frente a métodos tradicionales.

\section{Objetivos y alcances del proyecto}
En ésta sección se presenta el objetivo general, los objetivos específicos además del alcance y limitaciones de la presenta investigación.

\subsection{Objetivo general}
Evaluar el desempeño del algoritmo {\em simulated annealing} y su efecto sobre el entrenamiento de redes neuronales profundas en comparación con otros métodos. Los métodos que se comparan son: SGD, RMSProp y SA.

\subsection{Objetivos específicos}
Los objetivos establecidos para el presente trabajo son descritos a continuación
\begin{enumerate}
	\item Definir las reglas de aprendizaje a comparar.
	\item Construir los conjuntos de datos de entrada y salida a analizar.
	\item Establecer los parámetros de las redes neuronales para la experimentación.
	\item Establecer los algoritmos de aprendizaje a comparar.
	\item Entrenar las redes con los distintos conjuntos de datos.
	\item Establecer las conclusiones del trabajo.
\end{enumerate}

\subsection{Alcances}
\begin{enumerate}
	\item La arquitectura de las distitnas redes será la misma, variará solo el método de aprendizaje.
	\item Los conjunto de datos para el entrenamiento a utilizar son los propuestos en \cite{Morse2016}.
\end{enumerate}

\section{Metodología y herramientas utilizadas}
\subsection{Metodología de trabajo}
Considerando el aspecto investigativo del trabajo, se considera la utilización del método científico. Entre las actividades que componen la metodología, \citeA{Sampieri2006} describe los siguientes pasos para desarrollar una investigación:

\begin{itemize}
	\item Formulación de la hipótesis: Las redes neuronales que adolecen del desvanecimiento del gradiente tienen mejor convergencia al utilizar el algoritmo {\em simulated annealing} como método de aprendizaje.

	\item Marco teórico: Una revisión de la literatura donde se aborda el problema planteado, para situarse en el contexto actual de los problemas. Se describirán redes neuronales que buscan solucionar el mismo problema.

	\item Diseño de la solución: Se deberá diseñar el experimento para generar los datos que permitan sustentar las comparaciones entre las distintas redes.

	\item Análisis y verificación de los resultados: Los resultados se analizarán considerando los valores de convergencia de los distintos métodos.

	\item Presentación de los resultados: Se presentarán tablas que describan los resultados obtenidos y que se consideren pertinentes.

	\item Conclusiones obtenidas en el desarrollo de la investigación.
\end{itemize}

\subsection{Herramientas de desarrollo}
Para el desarrollo y ejecución de los experimentos se utilizará un equipo con las siguientes características
\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|}\hline
		Sistema Operativo	& Solus 2017.04.18.0 64-bit\\\hline
		Procesador				 & Intel$^\circledR$ Core\texttrademark i5-2450M CPU @ 2.50GHz x 4\\\hline
		RAM							  & 7.7Gb\\\hline
		Gráficos					& Intel$^\circledR$ Sandybridge Mobile\\\hline
		Almacenamiento	   & 935.6 GB\\\hline
	\end{tabular}
	\caption{Especificaciones del equipo}
\end{table}

El software que se utilizará es:
\begin{itemize}
	\item Lenguaje de programación: Python.
	\item Sistema de redes neuronales: Keras API \cite{Keras2015}.
	\item Herramienta ofimática: \LaTeX.
\end{itemize}
