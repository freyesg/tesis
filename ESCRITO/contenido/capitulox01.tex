\chapter{Introducción}
\section{Antecedentes y motivación}
%[Bishop] Neural Network for pattern recognition :: 77 y 116
Las redes neuronales ({\em Neural Networks}, NN) son sistemas de procesamiento de información que basan su estructura en una analogía de las redes neuronales biológicas. Consisten en un conjunto de elementos de procesamiento simple llamados nodos, estos nodos están dispuestos en una estructura jerarquica y conectadas entre sí por un valor numérico llamado peso que, mediante un proceso de entrenamiento, varia su valor.

La actividad que una neurona realiza en una NN consiste en ponderar las entradas de la neurona por los pesos de las conexiones de la neurona para luego ser sumadas y entregadas a la función de activación asociada \cite{McCulloch1943}. La salida corresponderá a la respuesta que la neurona genera a la entrada.

Las neuronas con una función de activación umbral, fueron estudiadas por \citeA{Rosenblatt1962} quién las denominó {\em perceptrón}. El modelo básico se compone de 3 capas conectadas consecutivamente. La primera capa corresponde a la capa de entrada, que recibe el patrón de entrada a clasificar. La segunda capa contiene las neuronas de asociación o detección de características. Y la tercera capa es la capa de salida, que contiene las neuronas que reconocen los patrones. La limitación de los perceptrones se debe a la capacidad de clasificación basado en el umbral, lo que no permite clasificar patrones más complejos.

El conjunto de $n$ neuronas se llamará capa, y una NN puede estar compuesta de una o más capas. Cada capa estará compuesta por una cantidad de neuronas que no necesariamente será la misma para todas las capas, y estarán dispuestas en forma consecutiva de tal manera que las capas se conecten unas con otras y siempre hacia adelante. La primera capa, la de entrada, recibirá un patrón que será entregado a las distintas neuronas que la capa posea. Cada neurona de la capa de entrada procesará los datos y generará una salida que servirá de entrada para la capa siguiente, repitiendo el proceso para cada una de las capas de la NN hasta llegar a la capa de salida, en cuyo caso la salida representará la respuesta de la red, concretando así el ciclo.

% https://www.neuraldesigner.com/blog/5_algorithms_to_train_a_neural_network
Las NN han sido utilizadas para la clasificación de entradas, y han sido diseñados diversos métodos para entrenar la red y que los pesos se adapten, de tal manera que la salida de la red sea representativa de la salida esperada; a este método de entrenamiento se le llama {\em supervisado}. Dentro de los métodos clásicos de entrenamiento se encuentra el método del gradiente descendente, el método de Newton, el gradiente conjugado, el método quasi-Newton, o el algoritmo Levenberg-Marquardt. El más utilizado es el método del gradiente, que consiste en actualizar los pesos de las distintas neuronas en función de la dirección contraría al gradiente de la función de activación, logrando minimizar el error.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% BACKPROPAGATION
La técnica de minimización más simple, cuando el gradiente está disponible, es seleccionar la dirección de descenso más empinada y aplicar una búsqueda unidireccional a lo largo de esta dirección. Esta técnica de optimización de descenso más pronunciada se define por

\begin{eqnarray}
	\Delta(n) W &=& -\lambda(n)G(n)
\end{eqnarray}

Donde $\Delta W(n)$ es la variación de los pesos para una iteración y $\lambda(n)$ es un coeficiente que minimiza la función en la dirección de descenso. %Se ha demostrado que no hay ventaja en encontrar el mínimo exacto en la dirección de búsqueda en cada iteración (Dennis y Schnabel, 1983).
El algoritmo de retropropagación propuesto por Werbos (1974) y popularizado por Rumelhart et al (1986) se basa en una variación de la técnica de pendiente más pronunciada. No se utiliza búsqueda unidireccional sino un paso de descenso fijo, $\eta$, llamado tasa de aprendizaje, que se añade a una fracción de la última variación, $\alpha$, llamada momentum. El último término introduce algunos elementos del método de gradiente conjugado. % Este algoritmo se define por:
%\begin{eqnarray}
%	\nabla_{p}W_{ij}^{(L)}(n) &=& -\eta G_{p_{ij}}^{(L)}(n) + \alpha\Delta_{p}W_{ij}^{L}(n - 1)
%\end{eqnarray}
%
%Al hacer una actualización continua por:
Así la actualización se realiza como en la ecuación \ref{eq:bp_wupdate}
\begin{eqnarray}
	W(n) &=& -\eta G(n) + \alpha\Delta W(n - 1)\label{eq:bp_wupdate}
\end{eqnarray}

%Cuando se elige un procedimiento de actualización por lotes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% MÉTODO QUASI-NEWTON
El método quasi-Newton utiliza el cálculo de las segundas derivadas de la función objetivo, se obtiene una mejor comprensión de la topología de la función, que conduce a su vez a elegir una dirección descendente más eficiente. Dejar:
\begin{eqnarray}
	\Delta W(n) &=& \lambda(n)S(n)
\end{eqnarray}

Donde la dirección de descenso S (n) está definida por:
\begin{eqnarray}
	S(n) &=& .[H(n)]^{-1}G(n)
\end{eqnarray}

Y donde $H(n)$ es la matriz Hessiana. La principal dificultad con este enfoque es que encontrar la solución de este sistema en cada iteración es una tarea muy tediosa. Los métodos métricos ariable, también llamados métodos cuasi-Newton, eluden esta dificultad aproximando directamente el inverso de la matriz de Hessiana, $[H(n)]^{-1}$, de la primera derivada, $G(n)$. Estos métodos son las técnicas de optimización sin restricciones más populares y, entre ellas, BGFS es el método más utilizado.% $[H(n)]^{-1}$ se calcular de la siguiente manera
%\begin{eqnarray}
%	\Delta[\hat{H}(n)]^{-1} &=& [\hat{H}(n + 1)]^{-1}-[\hat{H}(n)]^{-1}\\
%	\Delta[\hat{H}(n)]^{-1} &=& \\
%\end{eqnarray}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% GRADIENTE DESCENDENTE - BACKPROPAGATON
% [1996] Robitaille B, Marcos B, Veillette M, Payre G
%El gradiente descendente es el mas simple de los métodos. Este requiere información del gradiente del vector, por lo tanto corresponde a un método de primer orden. El método comienza en un punto inicial y, mientras el criterio de parada no se cumpla, la solución inicial se moverá en la dirección contraria al gradiente a razón de una taza de aprendizaje establecida. La taza de aprendizaje es quién decide cuan largo será el paso, si éste es muy grande, puede que la convergencia a la solución sea superada por un paso muy grande, en cambio, una taza de aprendizaje my pequeña puede demorar la convergencia.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% MÉTODO DE NEWTON
El método de Newton es un método de segundo orden, pues hace uso de la matriz Hessiana. El objetivo de este método es encontrar una mejor dirección de entrenamiento mediante el uso de la segunda derivada de la función de perdida. Considera una aproximación cuadrática de la función en la solución inicial utilizando una expansión de la serie de Taylor. De esta manera, el método de Newton permite mover la solución inicial en función de la inversa de la matriz Hessiana, que pasará a ser la dirección de entrenamiento de Newton.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% GRADIENTE CONJUGADO
% [1996] Robitaille B, Marcos B, Veillette M, Payre G
El método del gradiente del conjugado fue propuesto por \citeA{Fletcher1964}, utiliza sucesivas direcciones conjugadas basadas en el gradiente y el residuo. Si la función objetivo es cuadrática y la dirección de búsqueda es minimizada exactamente en cada iteración, el método converge de forma cuadrática. \citeA{Leonard1990} han utilizado el método para entrenar redes neuronales como alternativa a la retropropagación. Los pesos de una red se actualizan de acuerdo con una búsqueda unidencial en la dirección de descenso $S(n)$ de la siguiente forma:
\begin{eqnarray}
	\Delta W(n) = \lambda(n)S(n)
\end{eqnarray}

Y la dirección de descenso $S(n)$ se calcula a partir del gradiente de iteraciones pasadas y presentes como muestra la ecuación \ref{eq:s(n)}
\begin{eqnarray}
	S(n) &=& G(n) + \frac{||G(n)||}{||G(n - 1)||}S((n - 1))\label{eq:s(n)}
\end{eqnarray}

Para que las direcciones de descenso permanezcan conjugadas, la búsqueda unidirecional, en cada iteración, tiene que ser llevada con alta precisión. Sin embargo, después de muchas iteraciones, las direcciones podrían llegar a ser casi paralelas. Para superar esta dificultad, \citeA{Fletcher1964} sugieren volver a iniciar el procedimiento igualando la dirección de descenso al gradiente en cada iteración $(t + 1)$, donde $(t)$ es el número total de pesos en la red.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%\paragraph{Aprendizaje por corrección del error}: La salida de la NN se compara con la salida esperada, y la diferencia entre ambos valores se utiliza para corregir los pesos de las neuronas. Los pesos de las neuronas se ajustan en función de dicho error hasta ajustarse a los datos que se utilizan para el entrenamiento.

%\paragraph{Aprendizaje estocástico}: Consiste en modificar aleatoriamente los valores de los pesos y observar los resultados para evaluarlos respecto de la salida deseada. Las redes que utilizan este tipo de aprendizaje son una analogía de algún proceso físico basado en estados de energía, donde la red sería el grado de estabilidad y se buscaría el estado de mínima energía, que es el estado donde la respuesta de la red se ajusta de mejor manera a los datos. [37]

\section{Descripción del problema}
% USAR [2003b] Squartini S, Hussain A, Piazza F
La retropropagación basa su funcionamiento en multiplicaciones sucesivas basadas en el error para poder calcular los gradientes, y a medida que el error se propaga hacia la capa de entrada de la red el gradiente comienza a disminuír su valor por cada capa que atraviesa. Esto significa que el gradiente disminuirá de manera exponencial, lo que representa un problema para redes profundas, ya que las capas mas cercanas a la capa de entrada necesitarán más tiempo para ser entrenadas.

\section{Solución propuesta}
\subsection{Características de la solución}
Mediante el uso de el algoritmo {\em simulated annealing} se busca analizar la eficiencia que la NN alcanza en una red neuronal profunda frente a otros métodos de aprendizaje tales como: SGD y RMSPROP.

\subsection{Propósito de la solución}
El propósito de la solución es aportar en el campo de las redes neuronales y la clasificación de datos, proporcionando un análisis comparativo de la convergencia de distintas redes.

\section{Objetivos y alcances del proyecto}
En ésta sección se presenta el objetivo general, los objetivos específicos además del alcance y limitaciones de la presenta investigación.

\subsection{Objetivo general}
Evaluar el desempeño del algoritmo {\em simulated annealing} y su efecto sobre el entrenamiento de redes neuronales profundas en comparación con otros métodos.

\subsection{Objetivos específicos}
Los objetivos establecidos para el presente trabajo son descritos a continuación
\begin{enumerate}
	\item Definir las reglas de aprendizaje a comparar.
	\item Construir los conjuntos de datos de entrada y salida a analizar.
	\item Establecer los parámetros de las redes neuronales para la experimentación.
	\item Establecer los algoritmos de aprendizaje a comparar.
	\item Entrenar las redes con los distintos conjuntos de datos.
	\item Establecer las conclusiones del trabajo.
\end{enumerate}

\subsection{Alcances}
\begin{enumerate}
	\item Se analizará la misma arquitectura con diferentes reglas de aprendizaje.
	\item Los conjunto de datos para el entrenamiento a utilizar son los propuestos en \cite{Morse2016}.
\end{enumerate}

\section{Metodología y herramientas utilizadas}
\subsection{Metodología de trabajo}
Considerando el aspecto investigativo del trabajo, se considera la utilización del método científico. Entre las actividades que componen la metodología, \citeA{Sampieri2006} describe los siguientes pasos para desarrollar una investigación:

\begin{itemize}
	\item Formulación de la hipótesis: Las redes neuronales que adolecen del desvanecimiento del gradiente se ven beneficiadas por el uso del algoritmo {\em simulated annealing} en la convergencia.

	\item Marco teórico: Una revisión de la literatura donde se aborda el problema planteado, para situarse en el contexto actual de los problemas. Se describirán redes neuronales que buscan solucionar el mismo problema.

	\item Diseño de la solución: Se deberá diseñar el experimento para generar los datos que permitan sustentar las comparaciones entre las distintas redes.% Diseñar y ejecutar el experimento basado en entradas equivalentes.

	\item Análisis y verificación de los resultados: Los resultados se analizarán considerando los valores de convergencia de los distintos métodos.

	\item Presentación de los resultados: Se presentarán tablas que describan los resultados obtenidos y que se consideren pertinentes.

	\item Conclusiones obtenidas en el desarrollo de la investigación.
\end{itemize}

\subsection{Herramientas de desarrollo}
Para el desarrollo y ejecución de los experimentos se utilizará un equipo con las siguientes características
\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|}\hline
		Sistema Operativo	& Solus 2017.04.18.0 64-bit\\\hline
		Procesador				 & Intel$^\circledR$ Core\texttrademark i5-2450M CPU @ 2.50GHz x 4\\\hline
		RAM							  & 7.7Gb\\\hline
		Gráficos					& Intel$^\circledR$ Sandybridge Mobile\\\hline
		Almacenamiento	   & 935.6 GB\\\hline
	\end{tabular}
	\caption{Especificaciones del equipo}
\end{table}

El software que se utilizará es:
\begin{itemize}
	%\item Plataforma de desarrollo: Atom.
	\item Lenguaje de programación: Python.
	\item Sistema de redes neuronales: Keras API \cite{Keras2015}.
	\item Herramienta ofimática: \LaTeX.
\end{itemize}
