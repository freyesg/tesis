\chapter{Aspectos teóricos y revisión de la literatura}

En esta sección se abarcan los aspectos relacionados al conocimiento general para la comprensión del presente trabajo (aspectos teóricos) y la revisión de la literatura asociada al trabajo presentado en esta tesis. %Para realizar un análisis de la Programación Genética aplicada a problemas NP-Hard es necesario conocer la base teórica de ésta. Para ello, se exponen los conceptos fundamentales de la computación evolutiva y la Programación Genética. La sección 2.1 se centra en explicar aquellas partes fundamentales al tema que se trata en esta tesis. De la revisión de la literatura se desprende lo presentado en la sección 2.2.

%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Un párrafo para comparar los problemas conejillos de india con los que se compara. Para evaluar el desempeño de los algoritmos tipicamente se usan problemas problemas de aprendizaje de la literatura.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Las características del SGD y el problema del desvanecimiento. Las heurísticas y metaheurísticas.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Aspectos teóricos}
\subsection{Redes neuronales multicapas}
Una de las características que diferencia a las neuronas biológicas del resto de las células vivas, es su capacidad de comunicación. En la figura \ref{fig:neurona} se puede apreciar un esquema general de una neurona biológica. Las dendritas y el soma (cuerpo celular) reciben las señales de entrada; el cuerpo celular las combina e integra y emite una señal de salida. El axón transporta esas señales a los terminales axónicos, que se encargan de distribuir información a un nuevo conjunto de neuronas. Por lo general, una neurona recibe información de miles de otras neuronas, y a su vez, envía información a otras neuronas, formando una red de conexiones.
\begin{imagen}
	\scalebox{0.07}{\input{img/neurona}}
	\caption{Esquema de una neurona biológica.}
	\label{fig:neurona}
\end{imagen}

Una NN es un sistema de procesamiento basado en las conexiones que componen las redes neuronales biológicas y en la forma en que estas se comunican. Cada neurona tiene un estado interno, llamado de {\em activación}, que es una función de las entradas recibidas y envía su activación como señal a varias otras neuronas. Cada una está conectada a otras neuronas por medio de enlaces de comunicación dirigidos hacia adelante, formando capas, donde cada conexión tiene un peso asociado como se muestra en la figura \ref{fig:nn}. Los pesos representan la información que está siendo utilizada por la red para resolver un problema.
\begin{imagen}
	\scalebox{0.8}{\input{img/neural_network_img}}
	\caption{Esquema de una red neuronal}
	\label{fig:nn}
\end{imagen}

La activación de una neurona $Y$ está dado por su función de activación y las entradas. Alguna de las funciones de activación mas comunes se pueden ver en la tabla \ref{tab:f_activacion}. La entrada a la neurona $Y$ corresponde a la suma ponderada de los pesos de las conexiones que llegan hacia $Y$ por la salida de las neuronas de la capa anterior. En la figura \ref{fig:nn} se puede ver un modelo de tres capas, con una capa oculta. donde las salidas de las neuronas de la capa de entrada llegan hacia las neuronas $Y_1$ e $Y_2$ de la capa oculta para aplicar su función de activación respectiva, y sus salida son enviadas a la capa de salida.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|}\hline
		{\bf Función}	& {\bf Fórmula}	& {\bf Rango}\\\hline
		Identidad & $f(x) = x$	& $[-\infty, \infty]$\\\hline
		Lineal por tramos &
		$f(x) = \left\{
		\begin{array}{ll}
			-1		& x < -1\\
			a*x		& -1 \leq x \leq 1\\
			1		& x > 1
		\end{array}
		\right. $	& $[-1, 1]$\\\hline
		Sinusoidal	& $ f(x) = \sin(\omega x + \varphi) $	& $[-1, 1]$\\\hline
		Sigmoidal	& $f(x) = \frac{1}{1 + \exp{-x}}$	& $[0, 1]$\\\hline
		Tangente hiperbólica	& $\frac{1 - \exp(-x)}{1 + \exp(-x)}$	& $[-1, 1]$\\\hline
	\end{tabular}
	\caption{Algunas funciones de activaciones.}
	\label{tab:f_activacion}
\end{table}

Las NN multicapa definen una relación entre la entrada y la salida. Esta relación se obtiene propagando hacia adelante los valores de las variables de entrada, es por esto que también se les llama redes {\em feedforward}. Cada neurona de la red procesa la entrada recibida y produce una respuesta que se propaga, mediante las conexiones, hacia las neuronas de la capa siguiente.

Existen dos fases importante dentro del modelo
\begin{itemize}
	\item Fase de entrenamiento: Se usa un conjunto de datos o patrones de entrenamiento para determinar los pesos que definen el modelo de la NN. Se calculan de manera iterativa, de acuerdo con los valores de entrenamiento, con el objeto de minimizar el error cometido entre la salida obtenida por la NN y la salida deseada.

	Los pesos óptimos se obtienen minimizando una función. Uno de los criterios utilizados es la minimización del error cuadrático medio entre el valor de salida y el valor real esperado.

	\item Fase de prueba: Durante el entrenamiento, el modelo se ajusta al conjunto de entrenamiento, perdiendo la habilidad de generalizar su aprendizaje a casos nuevos, a esta situación se le llama sobreajuste.

	Para evitar el sobreajuste, se utiliza un segundo grupo de datos diferentes, el conjunto de validación, que permitirá controlar el proceso de aprendizaje.
\end{itemize}


\subsection{El algoritmo de entrenamiento por retropropagación}
El algoritmo de retropropagación del error, también conocido como la regla delta, fue el primer algoritmo de entrenamiento para redes multicapas  \cite{Werbos1974, Rumelhart1986}. El término retropropagación es utilizado debido a la forma de implementar el método del gradiente en las redes multicapa, pues el error cometido en la salida de la red es propagado hacia atrás, transformándolo en un error para cada una de las neuronas ocultas de la red..El entrenamiento de una red por retropropagación implica tres etapas: la propagación del patrón de entrada, el cálculo del error y su propagación hacia las capas anteriores, y el ajuste de los pesos. Después del entrenamiento, la aplicación de la red implica solamente los cálculos de la fase de propagación. En caso de que el entrenamiento sea lento, una red ya entrenada puede producir su salida rápidamente.


El funcionamiento del agoritmo de retropropagación se puede apreciar en la figura \ref{fig:backprop}. Se representa en azul primera fase del algoritmo, donde la entrada de la red se propaga hacia la salida a través de las neuronas transformandola en cada neurona de la red. La segunda fase, en verde, muestra como se propaga, desde la salida, el error hacia las capas anteriores. Finalmente, se puede ver en rojo como el algoritmo actualiza los pesos de la red utilizando el error que genera la red.
\begin{imagen}
	\scalebox{1.0}{\input{img/nn_parada}}
	\caption{Esquema del algoritmo de retropropagación.}
	\label{fig:backprop}
\end{imagen}

Si un perceptrón multicapa con $C$ capas y $n_c$ neuronas en la capa $c$, donde $W_c = (w^{c}_{ij})$ es la matriz de pesos, $w^{c}_{ij}$ representará el peso de la conexion de la neurona $i$ de la capa $c$ hasta la neurona $j$ de la capa siguiente. Denotaremos $a^{c}_{i}$ a la activación de la neurona $i$ de la capa $c$ que se calcula de la siguiente manera:
\begin{itemize}
	\item {\bf Activación de una neurona de la capa de entrada}: Las neuronas se encargan de transmitir la entrada recibida, por lo tanto $$ a^{1}_{i} = x_{i}, i = 1, 2, \cdots, n$$ donde $X = (x_1, x_2, \cdots, x_n)$ representa el vector de entrada.

	\item {\bf Activación de una neurona de la capa oculta}: Las neuronas de una capa oculta procesa la información recibida aplicando la función de activación $f$ a la suma de los productos de la entrada por sus pesos, es decir $$ a^{c}_{i} = f\left(\sum^{n_{c - 1}}_{j=1} w^{c - 1}_{ji}a^{c - 1}_{j} + \theta^{c}_{i}\right), i = 1, 2, \cdots, n_c; c = 2, 3, \cdots, C - 1$$ donde $a^{c - 1}_{j}$ es la salida de la capa anterior a $c$.

	\item {\bf Activación de una neurona de la capa de salida}: La activación de una neurona de la capa de salida viene dada por la función de activación $f$ aplicada a la suma de los productos de la entrada por sus pesos, es decir $$ y_{i} = a^{c}_{i} = f\left(\sum^{n_{c - 1}}_{j=1} w^{C - 1}_{ji}a^{C - 1}_{j} + \theta^{C}_{i}\right), i = 1, \cdots, n_c$$ donde $Y = (y_1, y_2, \cdots, y_{n_{c}})$ es el vector de salida.
\end{itemize}

La función $f$ es la función de activación de la neurona. Aunque existe gran variedad de funciones de activación (ver tabla \ref{tab:f_activacion}), las funciones de activación mas utilizadas son la sigmoidal y la tangente hiperbólica, descritas en las escuaciones \ref{eq:sigm} y \ref{eq:tanh} respectivamente.
\begin{eqnarray}
	f_{sigm}(x) &=& \frac{1}{1+\exp(-x)}\label{eq:sigm}\\
	f_{tanh}(x) &=& \frac{1 - \exp(-x)}{1 + \exp(-x)}\label{eq:tanh}
\end{eqnarray}

Ambas funciones poseen como imagen un intervalo de valores entre $[0, 1]$ y $[-1, 1]$ como se observa en la figura \ref{fig:funciones}.% y están descritas por las ecuaciones \ref{eq:sigm} y \ref{eq:tanh}.

\begin{imagen}
	\scalebox{1.0}{\input{img/funciones}}
	\caption{Funciones de activación mas utilizadas.}
	\label{fig:funciones}
\end{imagen}

Las NN multicapa actualiza sus pesos en función de una regla de aprendizaje, de tal manera que los nuevos pesos permitan reducir el error de salida. Por tanto, para cada patrón de entrada a la red es necesario disponer de un patrón de salida deseada. El objetivo es que la salida de la red sea lo más próxima posible a la salida deseada, debido a esto es que el aprendizaje de la red se describe como un problema de minimización de la siguiente manera $$ \min_{W} E $$ donde $W$ es el conjunto de parámetros de la red (pesos y umbrales) y $E$ es una función de error que evalúa la diferencia entre las salidas de la red y las salidas deseadas. En la mayor parte de los casos, la función de error se define como:
\begin{eqnarray}
	E = \frac{1}{N}\sum^{N}_{i = 1} e(i)
\end{eqnarray}

Donde $N$ es el número de muestras y $e(n)$ es el error cometido por la red para el patrón $i$, definido de la siguiente manera
\begin{eqnarray}
	e(i) = \frac{1}{n_{C}}\sum^{n_{C}}_{j = 1} (s_{j}(i) - y^{j}(n))^2\label{eq:error_patron}
\end{eqnarray}

Siendo $Y(i) = (y_{1}(i), y_{2}(i), \cdots, y_{n_{C}}(i))$ y $S(i) = (s_{1}(i), s_{2}(i), \cdots, s_{n_{C}}(i))$ los vectores de salida y salidas deseadas para el patrón $i$ respectivamente.

De esta manera, si $W^{*}$ es un mínimo de la función de error $E$, en dicho punto el error será cercano a cero, y en consecuencia, la salida de la red será próxima a la salida deseada. La presencia de funciones de activación no lineales hace que la respuesta de la red sea no lineal respecto a los parámetros ajustables, por lo que el problema de minimización es un problema no lineal y se hace necesario el uso de técnicas de optimización no lineales para su resolución.

Las técnicas utilizadas suelen basarse en la actualización de los parámetros de la red mediante la determinación de una dirección de búsqueda. En el caso de las NN multicapa, la dirección de búsqueda más utilizada se basa en la dirección contraria del gradiente de la función de error $E$, el método de gradiente descendente.

%Si bien el aprendizaje de la red busca minimizar el error total de la red, el procedimiento está basado en métodos del gradiente estocástico, que son una sucesión de minimizaciones del error $e(i)$ por cada patrón, en lugar de minimizar el error total $E$ de la red. Aplicando el método del gradiente estocástico, cada parámetro $w$ se modifica para cada patrón de entrada $n$ según la siguiente regla de aprendizaje
\begin{eqnarray}
	w(i) = w(n - 1) - \alpha\frac{\partial e(i)}{\partial w}
\end{eqnarray}

donde $e(i)$ es el error para el patrón de entrada $i$ dado por la ecuación \ref{eq:error_patron}, y $\alpha$ es la tasa de aprendizaje, éste último determina el desplazamiento en la superficie del error.





\section{Revisión de la literatura}
\subsection{El gradiente estocástico descendente}
\subsection{Rprop y RMSProp}
%\subsection{Retropropagación resiliente}
En las capas ocultas de las NN se utilizan con frecuencia funciones de activación sigmoidales, y estas reducen la entrada a un rango finito de salida. Se caracterizan por sus pendientes próximas a cero para entradas muy grandes, y esto representa un problema cuando se utiliza el gradiente descendente para el entrenamiento, pues se acentúa el problema del desvanecimiento del gradiente.

\citeA{Riedmiller1993} presenta el algoritmo de retropropagación resiliente ({\em Resilient retropropagation}, RPROP), con el que busca eliminar los efectos del desvanecimiento del gradiente, esto mediante el uso del signo de la derivada para determinar la dirección del ajuste de los pesos, haciendo que la magnitud de la derivada no tenga efecto sobre la actualización de los pesos de la NN. Los pesos de la NN se incrementarán por un factor $\Delta{i}$ cuando la derivada de la función respecto a dicho peso tenga el mismo signo que las dos iteraciones anteriores. Mientras que si la derivada de la función respecto a dicho peso cambia de signo respecto de la iteración anterior los pesos se decrementarán por un factor $\Delta_{d}$. En caso de que la derivada de la función respecto de dicho peso sea igual a cero, el valor de actualización no varía.

%\subsubsection{Root Mean Square RPROP}
\citeA{Tieleman2012} presentan el algoritmo de la raíz cuadratica media de retropropagación resiliente ({\em Root mean square resilient retropropagation}, RMSPROP), una variante  del algoritmo RPROP. Se propone mantener una media móvil del cuadrado del gradiente para cada peso
\begin{eqnarray}
	MeanSquare(w, t) &=& 0.9MeanSquare(w, t - 1) + 0.1\frac{\partial E}{\partial w^{(t)}}^{2}
\end{eqnarray}

Y dividiendo el gradiente por $\sqrt{MeanSquare(w, t)}$ hace que el aprendizaje funcione de mejor manera.


\subsection{Heurísticas y metaheurísticas}
\subsection{Simulated Annealing}
\subsection{Instancias}
