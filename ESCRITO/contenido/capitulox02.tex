\chapter{Aspectos teóricos y revisión de la literatura}

En esta sección se abarcan los aspectos relacionados al conocimiento general para la comprensión del presente trabajo (aspectos teóricos) y la revisión de la literatura asociada al trabajo presentado en esta tesis. %Para realizar un análisis de la Programación Genética aplicada a problemas NP-Hard es necesario conocer la base teórica de ésta. Para ello, se exponen los conceptos fundamentales de la computación evolutiva y la Programación Genética. La sección 2.1 se centra en explicar aquellas partes fundamentales al tema que se trata en esta tesis. De la revisión de la literatura se desprende lo presentado en la sección 2.2.

%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Un párrafo para comparar los problemas conejillos de india con los que se compara. Para evaluar el desempeño de los algoritmos tipicamente se usan problemas problemas de aprendizaje de la literatura.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%% IDEA %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Las características del SGD y el problema del desvanecimiento. Las heurísticas y metaheurísticas.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Aspectos teóricos}
\subsection{Redes neuronales multicapas}
Una de las características que diferencia a las neuronas biológicas del resto de las células vivas, es su capacidad de comunicación. En la figura \ref{fig:neurona} se puede apreciar un esquema general de una neurona biológica. Las dendritas y el soma (cuerpo celular) reciben las señales de entrada; el cuerpo celular las combina e integra y emite una señal de salida. El axón transporta esas señales a los terminales axónicos, que se encargan de distribuir información a un nuevo conjunto de neuronas. Por lo general, una neurona recibe información de miles de otras neuronas, y a su vez, envía información a otras neuronas, formando una red de conexiones.
\begin{imagen}
	\scalebox{0.07}{\input{img/neurona}}
	\caption{Esquema de una neurona biológica.}
	\label{fig:neurona}
\end{imagen}

Una NN es un sistema de procesamiento basado en las conexiones que componen las redes neuronales biológicas y en la forma en que estas se comunican. Cada neurona tiene un estado interno, llamado de {\em activación}, que es una función de las entradas recibidas y envía su activación como señal a varias otras neuronas. Cada una está conectada a otras neuronas por medio de enlaces de comunicación dirigidos hacia adelante, formando capas, donde cada conexión tiene un peso asociado como se muestra en la figura \ref{fig:nn}. Los pesos representan la información que está siendo utilizada por la red para resolver un problema.
\begin{imagen}
	\scalebox{0.8}{\input{img/neural_network_img}}
	\caption{Esquema de una red neuronal}
	\label{fig:nn}
\end{imagen}

La activación de una neurona $Y$ está dado por su función de activación y las entradas. Alguna de las funciones de activación mas comunes se pueden ver en la tabla \ref{tab:f_activacion}. La entrada a la neurona $Y$ corresponde a la suma ponderada de los pesos de las conexiones que llegan hacia $Y$ por la salida de las neuronas de la capa anterior. En la figura \ref{fig:nn} se puede ver un modelo de tres capas, con una capa oculta. donde las salidas de las neuronas de la capa de entrada llegan hacia las neuronas $Y_1$ e $Y_2$ de la capa oculta para aplicar su función de activación respectiva, y sus salida son enviadas a la capa de salida.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|c|c|}\hline
		{\bf Función}	& {\bf Fórmula}	& {\bf Rango}\\\hline
		Identidad & $f(x) = x$	& $[-\infty, \infty]$\\\hline
		Lineal por tramos &
		$f(x) = \left\{
		\begin{array}{ll}
			-1		& x < -1\\
			a*x		& -1 \leq x \leq 1\\
			1		& x > 1
		\end{array}
		\right. $	& $[-1, 1]$\\\hline
		Sinusoidal	& $ f(x) = \sin(\omega x + \varphi) $	& $[-1, 1]$\\\hline
		Sigmoidal	& $f(x) = \frac{1}{1 + \exp{-x}}$	& $[0, 1]$\\\hline
		Tangente hiperbólica	& $\frac{1 - \exp(-x)}{1 + \exp(-x)}$	& $[-1, 1]$\\\hline
	\end{tabular}
	\caption{Algunas funciones de activaciones.}
	\label{tab:f_activacion}
\end{table}

Las NN multicapa definen una relación entre la entrada y la salida. Esta relación se obtiene propagando hacia adelante los valores de las variables de entrada, es por esto que también se les llama redes {\em feedforward}. Cada neurona de la red procesa la entrada recibida y produce una respuesta que se propaga, mediante las conexiones, hacia las neuronas de la capa siguiente.

Existen dos fases importante dentro del modelo
\begin{itemize}
	\item Fase de entrenamiento: Se usa un conjunto de datos o patrones de entrenamiento para determinar los pesos que definen el modelo de la NN. Se calculan de manera iterativa, de acuerdo con los valores de entrenamiento, con el objeto de minimizar el error cometido entre la salida obtenida por la NN y la salida deseada.

	Los pesos óptimos se obtienen minimizando una función. Uno de los criterios utilizados es la minimización del error cuadrático medio entre el valor de salida y el valor real esperado.

	\item Fase de prueba: Durante el entrenamiento, el modelo se ajusta al conjunto de entrenamiento, perdiendo la habilidad de generalizar su aprendizaje a casos nuevos, a esta situación se le llama sobreajuste.

	Para evitar el sobreajuste, se utiliza un segundo grupo de datos diferentes, el conjunto de validación, que permitirá controlar el proceso de aprendizaje.
\end{itemize}


\subsection{El algoritmo de entrenamiento por retropropagación y el desvanecimiento del gradiente}
El algoritmo de retropropagación del error, también conocido como la regla delta, fue el primer algoritmo de entrenamiento para redes multicapas  \cite{Werbos1974, Rumelhart1986}. El término retropropagación es utilizado debido a la forma de implementar el método del gradiente en las redes multicapa, pues el error cometido en la salida de la red es propagado hacia atrás, transformándolo en un error para cada una de las neuronas ocultas de la red. El entrenamiento de una red por retropropagación implica tres etapas: la propagación del patrón de entrada, el cálculo del error y su propagación hacia las capas anteriores, y el ajuste de los pesos. Después del entrenamiento, la aplicación de la red implica solamente los cálculos de la fase de propagación. En caso de que el entrenamiento sea lento, una red ya entrenada puede producir su salida rápidamente.


El funcionamiento del agoritmo de retropropagación se puede apreciar en la figura \ref{fig:backprop}. Se representa en azul primera fase del algoritmo, donde la entrada de la red se propaga hacia la salida a través de las neuronas transformandola en cada neurona de la red. La segunda fase, en verde, muestra como se propaga, desde la salida, el error hacia las capas anteriores. Finalmente, se puede ver en rojo como el algoritmo actualiza los pesos de la red utilizando el error que genera la red.
\begin{imagen}
	\scalebox{1.0}{\input{img/nn_parada}}
	\caption{Esquema del algoritmo de retropropagación.}
	\label{fig:backprop}
\end{imagen}

Si un perceptrón multicapa con $C$ capas y $n_c$ neuronas en la capa $c$, donde $W_c = (w^{c}_{ij})$ es la matriz de pesos, $w^{c}_{ij}$ representará el peso de la conexion de la neurona $i$ de la capa $c$ hasta la neurona $j$ de la capa siguiente. Denotaremos $a^{c}_{i}$ a la activación de la neurona $i$ de la capa $c$ que se calcula de la siguiente manera:
\begin{itemize}
	\item {\bf Activación de una neurona de la capa de entrada}: Las neuronas se encargan de transmitir la entrada recibida, por lo tanto $$ a^{1}_{i} = x_{i}, i = 1, 2, \cdots, n$$ donde $X = (x_1, x_2, \cdots, x_n)$ representa el vector de entrada.

	\item {\bf Activación de una neurona de la capa oculta}: Las neuronas de una capa oculta procesa la información recibida aplicando la función $f$ a la suma de los productos de la entrada por sus pesos, es decir $$ a^{c}_{i} = f\left(\sum^{n_{c - 1}}_{j=1} w^{c - 1}_{ji}a^{c - 1}_{j} + \theta^{c}_{i}\right), i = 1, 2, \cdots, n_c; c = 2, 3, \cdots, C - 1$$ donde $a^{c - 1}_{j}$ es la salida de la capa anterior a $c$.

	\item {\bf Activación de una neurona de la capa de salida}: La activación de una neurona de la capa de salida viene dada por la función $f$ aplicada a la suma de los productos de la entrada por sus pesos, es decir $$ y_{i} = a^{c}_{i} = f\left(\sum^{n_{c - 1}}_{j=1} w^{C - 1}_{ji}a^{C - 1}_{j} + \theta^{C}_{i}\right), i = 1, \cdots, n_c$$ donde $Y = (y_1, y_2, \cdots, y_{n_{c}})$ es el vector de salida.
\end{itemize}

La función $f$ es la función de activación de la neurona. Aunque existe gran variedad de funciones de activación (ver tabla \ref{tab:f_activacion}), las funciones de activación mas utilizadas son la sigmoidal y la tangente hiperbólica, descritas en las escuaciones \ref{eq:sigm} y \ref{eq:tanh} respectivamente.
\begin{eqnarray}
	f_{sigm}(x) &=& \frac{1}{1+\exp(-x)}\label{eq:sigm}\\
	f_{tanh}(x) &=& \frac{1 - \exp(-x)}{1 + \exp(-x)}\label{eq:tanh}
\end{eqnarray}

Ambas funciones poseen como imagen un intervalo de valores entre $[0, 1]$ y $[-1, 1]$ como se observa en la figura \ref{fig:funciones}.% y están descritas por las ecuaciones \ref{eq:sigm} y \ref{eq:tanh}.

\begin{imagen}
	\scalebox{1.0}{\input{img/funciones}}
	\caption{Funciones de activación mas utilizadas.}
	\label{fig:funciones}
\end{imagen}

Las NN multicapa actualizan sus pesos en función de una regla de aprendizaje, de tal manera que los nuevos pesos permitan reducir el error de salida. Por tanto, para cada patrón de entrada necesario disponer de una de salida deseada. El objetivo es que la salida de la red sea lo más próxima posible a la salida deseada, debido a esto es que el aprendizaje de la red se describe como un problema de minimización de la siguiente manera $$ \min_{W} E $$ donde $W$ es el conjunto de parámetros de la red (pesos y umbrales) y $E$ es una función de error que evalúa la diferencia entre las salidas de la red y las salidas deseadas. En la mayor parte de los casos, la función de error se define como:
\begin{eqnarray}
	E = \frac{1}{N}\sum^{N}_{i = 1} e(i)
\end{eqnarray}

Donde $N$ es el número de muestras y $e(n)$ es el error cometido por la red para el patrón $i$, definido de la siguiente manera
\begin{eqnarray}
	e(i) = \frac{1}{n_{C}}\sum^{n_{C}}_{j = 1} (s_{j}(i) - y^{j}(n))^2\label{eq:error_patron}
\end{eqnarray}

Siendo $Y(i) = (y_{1}(i), y_{2}(i), \cdots, y_{n_{C}}(i))$ y $S(i) = (s_{1}(i), s_{2}(i), \cdots, s_{n_{C}}(i))$ los vectores de salida y salidas deseadas para el patrón $i$ respectivamente.

De esta manera, si $W^{*}$ es un mínimo de la función de error $E$, en dicho punto el error será cercano a cero, y en consecuencia, la salida de la red será próxima a la salida deseada. La presencia de funciones de activación no lineales hace que la respuesta de la red sea no lineal respecto a los parámetros ajustables, por lo que el problema de minimización es un problema no lineal y se hace necesario el uso de técnicas de optimización no lineales para su resolución.

Las técnicas de actualización utilizadas suelen basarse en la actualización de los parámetros de la red mediante la determinación de una dirección de búsqueda. En el caso de las NN multicapa, la dirección de búsqueda más utilizada se basa en la dirección contraria del gradiente de la función de error $E$, el método de gradiente descendente. El procedimiento está basado en una sucesión de minimizaciones del error $e(i)$ por cada patrón, en lugar de minimizar el error total $E$ de la red. Aplicando el método cada parámetro $w$ se modifica según la siguiente regla de aprendizaje
\begin{eqnarray}
	w(i) = w(i - 1) - \alpha\frac{\partial e(i)}{\partial w}\label{eq:update}
\end{eqnarray}
donde $e(i)$ es el error para el patrón de entrada $i$ dado por la ecuación \ref{eq:error_patron}, y $\alpha$ es la tasa de aprendizaje, éste último determina el desplazamiento en la superficie del error.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DESVANECIMIENTO DEL GRADIENTE
A medida que el error se propaga a través de la red, los pesos se actualizarán según la ecuación \ref{eq:update}, utilizando funciones cuyo gradiente se encuentra entre 0 y 1. Debido a que estos gradientes se multiplican durante la retropropagación, tienden a {\em desvanecerse} a través de las capas, y en una NN profunda esto evita que los pesos de las primeras capas ocultas se actualicen minimamente.

Si se tiene una NN, la activación de una neurona de una capa intermedia $i$ con función de activación $f$ es $y^{i}(t) =  f_{i}(net_{i}(t))$ donde $$ net_{i}(t) = \sum_{j}w_{ji}y^{j}(t - 1) $$ es la entrada a la neurona. Además $w_{ji}$ es el peso de la conexión desde la unidad $j$ de la capa anterior hasta la unidad $i$ de la capa actual, $d_{k}(t)$ será la respuesta esperada de la unidad $k$ de la capa de salida en el tiempo $t$. Usando el error cuadrático medio ({\em Mean square error}, MSE), el error de $k$ será
$$ E_{k}(t) = (d_{k}(t) - y^{k}(t))^2 $$



%Si se tiene una NN, la activación de una neurona de una capa intermedia $i$ con función de activación $f_i$ y con entrada $$ net_{i}(t) = \sum_{j}w_{ji}y^{j}(t - 1) $$ es $$y^{i}(t) = f_{i}(net_{i}(t))$$ Además $w_{ji}$ es el peso de la conexión desde la unidad $j$ de la capa anterior hasta la unidad $i$ de la capa actual, $d_{k}(t)$ será la respuesta esperada de la unidad $k$ de la capa de salida en el tiempo $t$. Usando el error cuadrático medio ({\em Mean square error}, MSE), el error de $k$ será $$ E_{k}(t) = (d_{k}(t) - y^{k}(t))^2 $$

En un tiempo $\tau \leq t$ cualquiera, el error de una neurona $j$ que no sea una neurona de entrada es la suma de los errores externos y el error propagado hacia atrás desde la neurona previa será
$$ \vartheta_{j}(\tau) = f'_{j}(net_{j}(\tau))\left(E_{j}(\tau) + \sum_{i} w_{ij}\vartheta_{i}(\tau + 1)\right) $$

El peso actualizado en el tiempo $\tau$ resulta $w_{jl}^{new} = w_{jl}^{old} + \alpha\vartheta_{j}(\tau) y^{l}(\tau - 1)$ donde $\alpha$ es la tasa de aprendizaje, y $l$ es una unidad arbitraria conectada a la unidad $j$.

%\citeA{Puskorius1994}
La propagación hacia atrás de un error que ocurre en una unidad $u$ en un tiempo $t$ hacia una unidad $v$ para $q$ pasos, escala el error de la siguiente manera
\begin{eqnarray}
\frac{\partial\vartheta_{v}(t - q)}{\partial\vartheta_{u}(t)} =
\left\{
\begin{array}{lr}
	f^{'}_{v}(net_{v}(t - 1))w_{uv}	& q = 1\\
	\\
	f^{'}_{v}(net_{v}(t - q))\sum^{n}_{l=1}\frac{\partial\vartheta(t - q + 1)}{\partial\vartheta_{u}(t)}w_{lv}	& q > 1
\end{array}
\right.
\end{eqnarray}

Con $l_{q} = v$ y $l_{0} = u$, el factor de escalamiento es
\begin{eqnarray}
\frac{\partial\vartheta_{v}(t - q)}{\partial\vartheta_{u}(t)} =
\sum^{n}_{l_{1}=1}\cdots\sum^{n}_{l_{q - 1}=1}\prod^{q}_{m = 1}f^{'}_{l_{m}}(net_{l_{m}}(t - m))w_{l_{m}l_{m - 1}}\label{eq:vanishing}
\end{eqnarray}

La sumatoria de los $n^{q - 1}$ términos $\prod^{q}_{m = 1}f^{'}_{l_{m}}(net_{l_{m}}(t - m))w_{l_{m}l_{m - 1}}$ escalan el error. Los distintos términos pueden tener signos diferentes, por lo tanto, el aumento del número de unidades $n$ no implica un incremento del error absoluto. Pero con mas unidades se incrementa la expectativa de que el valor absoluto del error aumente. Si $\rho(m, l_{m}, l_{m - 1}) := |f^{'}_{l_{m}}(net_{l_{m}}(t - m))w_{l_{m}l_{m - 1}}| < 1.0$
para todo $m$, el producto en (\ref{eq:vanishing}) decrece exponencialmente con $q$, es decir, el error se desvanece como muestra la figura \ref{fig:vanishing}. Un error que se desvanece a lo largo del flujo casi no tiene efecto en la actualización de los pesos. %Dada la constante $y^{l_{m - 1}} \neq 0$, $\rho(m, l_{m}, l_{m - 1})$ es máximo cuanto $w_{l_{m}l_{m - 1}} = \frac{1}{y^{l_{m - 1}}}\coth(\frac{net_{l_{m}}}{2})$.

\begin{imagen}
	\scalebox{1.0}{\input{img/vanishing_img}}
	\caption{Gradiente descendente}
	\label{fig:vanishing}
\end{imagen}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Revisión de la literatura}
\subsection{El gradiente estocástico descendente}
\subsection{Retropropagación resiliente y RMSProp}
%\subsection{Retropropagación resiliente}
En las capas ocultas de las NN se utilizan con frecuencia funciones de activación sigmoidales, y estas reducen la entrada a un rango finito de salida. Se caracterizan por sus pendientes próximas a cero para entradas muy grandes, y esto representa un problema cuando se utiliza el gradiente descendente para el entrenamiento, pues se acentúa el problema del desvanecimiento del gradiente.

\citeA{Riedmiller1993} presenta el algoritmo de retropropagación resiliente ({\em Resilient retropropagation}, RPROP), con el que busca eliminar los efectos del desvanecimiento del gradiente, esto mediante el uso del signo de la derivada para determinar la dirección del ajuste de los pesos, haciendo que la magnitud de la derivada no tenga efecto sobre la actualización de los pesos de la NN. Los pesos de la NN se incrementarán por un factor $\Delta{i}$ cuando la derivada de la función respecto a dicho peso tenga el mismo signo que las dos iteraciones anteriores. Mientras que si la derivada de la función respecto a dicho peso cambia de signo respecto de la iteración anterior los pesos se decrementarán por un factor $\Delta_{d}$. En caso de que la derivada de la función respecto de dicho peso sea igual a cero, el valor de actualización no varía.

%\subsubsection{Root Mean Square RPROP}
\citeA{Tieleman2012} presentan el algoritmo de la raíz cuadratica media de retropropagación resiliente ({\em Root mean square resilient retropropagation}, RMSPROP), una variante  del algoritmo RPROP. Se propone mantener una media móvil del cuadrado del gradiente para cada peso
\begin{eqnarray}
	MeanSquare(w, t) &=& 0.9MeanSquare(w, t - 1) + 0.1\frac{\partial E}{\partial w^{(t)}}^{2}
\end{eqnarray}

Y dividiendo el gradiente por $\sqrt{MeanSquare(w, t)}$ hace que el aprendizaje funcione de mejor manera.


\subsection{Heurísticas y meta-heurísticas}
Hoy en día, resolver problemas computacionalmente complejos precisa el desarrollo de algoritmos más avanzados. Los algoritmos exactos a menudo utilizan una gran cantidad de tiempo debido al tamaño del espacio de soluciones factibles. Para resolver este inconveniente, se han diseñado algoritmos aproximados basados en el uso de heurísticas y meta-heurísticas, los que permiten encontrar soluciones que se aproximan a la mejor solución. Estos algoritmos utilizan funciones que están diseñadas para encontrar el espacio de soluciones de forma inteligente.

La figura \ref{fig:tax_opt} muestra la clasificación de diferentes problemas de optimización, los que se categorizan en: algoritmos exactos y algoritmos aproximados \cite{Desale2015}
%En la Figura \ref{fig:tax_opt} se muestra la clasificación de diferentes problemas de optimización, los cuales están divididos en dos categorías: algoritmos exactos y algoritmos aproximados \cite{Desale2015}.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.2]{img/tax_opt.png}
    \caption{Métodos para resolver problemas de optimización \protect\cite{Desale2015}.}
		\label{fig:tax_opt}
\end{figure}

Los algoritmos meta-heurísticos son un proceso iterativo que guía una heurística para explorar el espacio de búsqueda. Estos tipos de algoritmos son utilizados para encontrar una solución en un espacio de búsqueda discreto en problemas de optimización combinatoria.

%Las heurísticas y meta-heurísticas son utilizadas para encontrar una solución óptima en un espacio de búsqueda discreto en problemas de optimización combinatoria. Un ejemplo es el problema del vendedor viajero, donde la búsqueda del espacio de soluciones factibles crece exponencialmente en función del tamaño del problema aumenta, lo que hace inviable la realización de una búsqueda exhaustiva de la solución óptima \cite{Desale2015}.




\subsection{Simulated Annealing}
\subsection{Instancias}
